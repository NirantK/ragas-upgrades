metric,total_row_count,total_metric_frequency,events_covered,records
faithfulness,11582775,3599579,1,451
answer_relevancy,10234385,3331326,1,423
answer_correctness,2257844,1088832,1,306
context_recall,1936109,991912,1,386
context_precision,1268293,592550,1,326
semantic_similarity,951169,409271,1,155
llm_context_precision_without_reference,670009,364218,1,27
factual_correctness,648317,335107,1,64
context_relevancy,1535580,264239,1,58
answer_similarity,514311,224482,1,163
e2e_accuracy,1335482,219400,1,4
context_relevance,847840,218985,1,4
response_groundedness,849483,216894,1,3
llm_context_precision_with_reference,478730,160256,1,31
context_entity_recall,264802,160162,1,103
rouge_score,2240410,153447,1,24
coherence,165896,142525,1,35
harmfulness,139661,113240,1,95
completeness,116942,112823,1,3
relevance,113300,108740,1,3
coverage,106658,102959,1,1
maliciousness,318283,97995,1,33
bleu_score,1133703,97842,1,4
consistency,105955,96177,1,1
non_llm_string_similarity,5922504,89641,1,12
noise_sensitivity,82178,77706,1,1
context_utilization,117931,58212,1,58
correctness,130230,45300,1,31
reversed_answer_correctness,73949,42882,1,1
summary_score,70203,41222,1,8
noise_sensitivity_relevant,62916,40785,1,32
conciseness,58375,38934,1,37
nv_accuracy,98165,29308,1,1
bias,28926,28926,1,2
domain_specific_rubrics,49870,27259,1,2
non_llm_context_precision_with_reference,89031,24447,1,7
non_llm_context_recall,103401,22406,1,4
faithfulness_with_hhem,28918,20791,1,2
nv_context_relevance,71016,14531,1,1
summary_accuracy,30915,12041,1,1
equivalence_score,11143,11143,1,1
goal_achievement_v2_1,49066,10748,1,2
nv_response_groundedness,57555,9938,1,1
topic_adherence,9946,7758,1,1
paragraph_faithfulness,7572,7572,1,1
exact_match,609665,7551,1,32
llm_sql_equivalence_with_reference,10511,6863,1,1
agent_goal_accuracy,7772,5833,1,1
faithful_rate,11254,4161,1,5
relevance_rate,10112,3912,1,3
rag_score,10198,3716,1,1
conciseness_and_efficiency_metric,7012,3455,1,1
contextual_relevance_and_usefullnes_metric,6948,3403,1,1
coherence_and_clarity_metric,6988,3384,1,1
precision,7052,3383,1,1
completness_metric,6897,3333,1,1
accuracy,133874,3318,1,2
recall,6340,3310,1,1
binary_correctness,3158,3158,1,1
data_compare_score,64653,2836,1,1
sme_accuracy,5767,2752,1,1
sme_precision,5583,2641,1,1
flowvalidationsaccuracy_make_a_payment_amount_validation,2637,2637,1,2
toxicityai,2624,2624,1,2
flowvalidationsaccuracy_make_a_payment_add_debit_card_validation,2621,2621,1,2
testscenarioaccuracyai,2619,2619,1,2
flowvalidationsaccuracy_make_a_payment_add_bank_account_validation,2618,2618,1,2
factualaccuracy,2617,2617,1,2
flowvalidationsaccuracy_make_a_payment_payment_method_validation,2615,2615,1,2
testscenarioaccuracyuser,2615,2615,1,2
sme_coverage,5382,2567,1,1
sme_style,5354,2567,1,1
interestingness,2430,2120,1,1
humanness,2458,2118,1,1
making_sense,2414,2113,1,1
fluency,2400,2089,1,1
repetition,2323,2061,1,1
engagingness,2355,2051,1,1
knowledgability,2151,1938,1,1
tool_call_accuracy,6346,1914,1,1
listening,2099,1909,1,1
inquisitiveness,2121,1904,1,1
string_present,12513,1631,1,10
eis_fidelity,4769,1497,1,2
citation_score,1459,1459,1,1
answer_correctness_custom,1365,1365,1,1
factual_correctness_from_answer_correctness,2079,1213,1,1
semantic_similarity_from_answer_correctness,2023,1191,1,1
code_bleu,7616,1148,1,2
llm_faithfulness,4499,1116,1,1
llm_kql_equivalence_with_reference,8371,979,1,1
eis_answer_correctness,978,978,1,1
eis_answer_relevancy,978,978,1,1
hallucinations_rubric,1117,951,1,3
citation_quality,1527,943,1,1
answer_depth,1508,925,1,1
rubrics_score_with_reference,1106,922,1,2
answer_coherence,1461,917,1,1
ragas_answer_correctness,2483,916,1,1
answer_completeness,1438,908,1,1
answer_clarity,1408,880,1,1
ragas_factual_correctness,2490,876,1,1
ragas_semantic_similarity,2486,837,1,1
course_grained_score,944,756,1,1
noise_sensitivity_irrelevant,4699,679,1,6
answer_precision,6387,560,1,9
answer_recall,5871,533,1,12
correctness_custom,3087,528,1,1
expert_question_answering,523,523,1,1
flowvalidationsaccuracy_make_a_payment_payment_authorisation_validation,511,511,1,1
answer_relevance,508,508,1,1
answered_binary,587,452,1,1
general_eval_metric,591,449,1,1
answer_provided,580,448,1,1
hallucinations_binary,606,408,1,3
toxicity,577,404,1,2
hallucinations,437,378,1,1
dexpert_answer_relevancy,372,372,1,1
dexpert_context_relevancy,372,372,1,1
dexpert_faithfulness,372,372,1,1
rephrase_accuracy,1331,368,1,1
ragas_faithfulness,1770,365,1,2
answer_usability,1337,363,1,1
repetitiveness_score,1978,341,1,1
homogenization,384,337,1,1
guideline_compliance,3200,327,1,1
routing_accuracy,971,316,1,1
personal_finance_relevancy,480,316,1,1
is_relevant,3957,307,1,1
answer_comparison,300,300,1,1
cs_quality,30948,298,1,1
harmful_bias,331,294,1,1
competencia_rubric,321,294,1,1
tone_appropriateness,927,282,1,1
rougel,1088,248,1,1
user_name_check,452,237,1,1
lack_empathy,278,227,1,1
answer_relevancy_rubric,2880,225,1,1
finalresponseaccuracy,923,224,1,1
black_bias,260,222,1,1
rag_quality,716,218,1,1
agent_name_check,367,217,1,1
hispanic_bias,269,216,1,1
refusal_rate,239,214,1,1
rouge1,697,211,1,1
structural_validation,210,210,1,1
rouge2,697,209,1,1
organization_name_check,365,209,1,1
comprension_necesidades_locales_rubric,235,209,1,1
relevance_rubric,238,206,1,1
adecuacion_cultural_rubric,235,206,1,1
user_centric_rubric,233,206,1,1
seguridad_percibida_rubric,232,206,1,1
apego_normas_para_sugerir_rubric,237,205,1,1
redundant_rubric,237,205,1,1
hallucinations_metric,368,204,1,3
engagement_rubric,236,204,1,1
lenguaje_inclusivo_rubric,236,204,1,1
corectness_custom,359,200,1,1
responsecorrectness,206,198,1,1
coverage_scorer,418,196,1,1
uso_de_malas_palabras_rubric,221,196,1,1
consistencia_rubric,215,196,1,1
uso_de_tecnicalidades_rubric,215,196,1,1
tono_del_agente_rubric,216,194,1,1
datos_personales_rubric,210,190,1,1
legis_contain_normative_rule,723,187,1,1
aspect_critique,249,181,1,1
relevance_scorer,373,180,1,1
excess_scorer,372,177,1,1
correctness_scorer,369,177,1,1
sql_accuracy,493,174,1,1
forgetfulness_aspect_critic,224,172,1,1
is_reject,1882,161,1,1
summaryaccuracy,160,160,1,1
legis_conciseness,435,155,1,1
style_guideline_metric,168,154,1,1
summary_structure_metric,168,154,1,1
attack_extraction,576,151,1,1
bias_evaluation,142,142,1,1
legis_check_explanation,334,136,1,1
factual_correctness_f1,1530,130,1,8
meteor_metric,1524,125,1,14
legal_correctness,169,124,1,1
answer_accuracy,345,122,1,1
answer_f1,2326,121,1,2
statements_num_answer_only,2326,121,1,2
statements_num_gt_only,2326,121,1,2
statements_overlap,2326,121,1,2
answers_question,318,121,1,1
cosine spread,5067,117,1,1
rejection,559,115,1,1
specificity,183,112,1,1
factual_correctness_recall,1082,109,1,6
factual_correctness_precision,1077,108,1,6
coverage_accuracy,282,107,1,1
clarity,272,106,1,1
helpfulness,1268,105,1,1
cta_effectiveness,279,105,1,1
data_support,276,105,1,1
reference_free_rubrics_score,103,103,1,1
name_leak,111,102,1,1
address_leak,108,99,1,1
answerquality,1017,98,1,2
date_leak,108,98,1,1
answer recall,123,97,1,1
institution_leak,110,97,1,1
readability,97,96,1,1
poc_notebook_rubrics,96,94,1,1
response_relevancy,186,93,1,1
other_leak,100,93,1,1
placeholder,455,92,1,1
accurateness,708,91,1,1
truthfulness,148,91,1,1
wait_time_acknowledgement,116,91,1,1
misrepresentation_source,90,90,1,1
important_entities,89,89,1,1
shared_page,89,89,1,1
translation_faithfulness,806,88,1,1
main_point,88,88,1,1
not_for_insights,88,88,1,1
ra一致性,94,87,1,1
irrelevancy,87,87,1,1
question_relevance,715,86,1,1
misinterpretation,86,86,1,1
misrepresentation_research,86,86,1,1
context_recall_mtstep,18319,85,1,1
specificity_metric_llm_rating,1415,85,1,5
made_up_info,85,85,1,1
specificity_metric_final_score,1415,84,1,5
specificity_metric_ner_score,1206,84,1,4
correct_number,83,83,1,1
specificity_metric_llm_score,1205,82,1,4
answer precision,130,82,1,1
specificity_metric_depth_score,1202,81,1,4
hallucination_rubric,340,81,1,1
accuracy_rubric,324,81,1,1
hallucination,83,81,1,2
summaryfaithfulness,81,81,1,1
topicality_rubric,341,80,1,1
topic_adherence_recall,162,79,1,1
topic_adherence_precision,167,78,1,1
topic_adherence_f1,162,77,1,1
ca召回率,79,77,1,1
eis_answer_relevance,172,76,1,5
ra相关性,80,76,1,1
ca精确率,76,76,1,1
categorization_accuracy,202,75,1,1
eis_section_structure,171,75,1,4
eis_faithfulness,170,74,1,3
eis_context_precision,169,73,1,2
statements_answer_only,518,72,1,1
statements_gt_only,518,72,1,1
statements_num_overlap,518,72,1,1
eis_context_recall,168,72,1,1
rc一致性,78,71,1,1
qr相关性,75,71,1,1
in_favor_of_fivetran,71,71,1,1
usefulness_metric,1098,67,1,4
if_reject,793,67,1,1
translation_correctness,193,67,1,1
amazon_answer_relevancy,97,67,1,1
amazon_context_relevancy,97,67,1,1
amazon_faithfulness,97,67,1,1
exhibit_quality_validation,67,67,1,1
tab_structure_validation,67,67,1,1
fc_f1,2292,66,1,2
fc_precision,2292,66,1,2
fc_recall,2292,66,1,2
timing_format_validation,66,66,1,1
response_accuracy,107,64,1,1
is_contradict,600,63,1,1
scenario_necessity_validation,63,63,1,1
stem_neutrality_validation,63,63,1,1
ragas_nonllmcontextprecisionwithreference,66,61,1,1
grounded,12567,60,1,1
pertinence,12567,60,1,1
comprension_rubric,76,60,1,1
ragas_nonllmcontextrecall,65,60,1,1
vitals_format_validation,57,57,1,1
alucinacion_rubric,63,56,1,1
metadata_accuracy,117,55,1,1
coarse_grained_score,55,54,1,1
overview_correctness,54,54,1,1
label_sim,1730,53,1,1
semantic_search_relevance,265,53,1,1
area_correctness,2502,52,1,1
retrieval_precision,1421,52,1,1
redundancy_aspect_critic,51,51,1,1
multi_sim,2254,49,1,1
custom_verbosity,79,47,1,1
回答是否准确,56,47,1,1
legacy_rubrics,48,47,1,1
ragas_llmcontextprecisionwithoutreference,58,46,1,1
ragas_semanticsimilarity,48,46,1,1
dependency_coverage,64,45,1,1
format_compliance,61,45,1,1
no_information_retrieved_binary,48,45,1,1
excerpt_accuracy,143,43,1,1
information_completeness,119,43,1,1
ragas_contextentityrecall,59,43,1,1
ragas_llmcontextrecall,54,43,1,1
credibility,43,43,1,1
emphasis,43,43,1,1
f1_metric,43,43,1,1
privacy_binary,114,42,1,1
technical_depth,63,41,1,1
response_grader,44,41,1,1
准确性,208,40,1,1
context_precision_with_reference,57,40,1,1
constant,46,39,1,1
qr全面性,39,39,1,1
discover_with_references,1520,38,1,2
authenticity,38,38,1,2
translation_accuracy,176,36,1,1
politeness,70,36,1,1
ragas_responserelevancy,40,36,1,1
context_precision_without_reference,57,34,1,1
call_to_action_effectiveness,80,33,1,1
data_driven_justification,78,33,1,1
ragas_llmcontextprecisionwithreference,52,33,1,1
retrivalprecision,33,33,1,1
instance_rubrics,61,32,1,1
hallucination_arithmetic_detector,253,31,1,2
hallucination_detector,306,30,1,2
usefulness metric,90,30,1,2
bert_score,84,30,1,1
context_utilization_metric,30,30,1,1
score,139,29,1,1
bleu,29,29,1,1
nonllmstringsimilarity,28,28,1,1
stringpresence,28,28,1,1
recall_metric,27,27,1,1
trait_accuracy,27,27,1,1
doc_retrieval_metric,480,26,1,1
completeness_metric,272,25,1,1
specificity metric,75,25,1,6
conciseness_check,25,25,1,1
q&a,25,25,1,1
verbose_faithfulness,48,24,1,1
factual_correctness_atomlo_covhi,31,24,1,1
test_rubria_custom_rubric,30,24,1,1
coherence_metric,271,23,1,1
orm_accuracy_metric,439,22,1,1
labelled_rubrics_score,275,22,1,1
factual_correctness_atomhi_covlo,28,22,1,1
factual_correctness_f1_nlistatementprompt,28,22,1,1
relate,22,22,1,1
able,1547,21,1,1
give_answer,1547,21,1,1
not_assistant_in_answer,1547,21,1,1
same_language,1547,21,1,1
time_elapsed,1547,21,1,1
accucary,430,21,1,1
factual_correctness_atomhi_covhi,25,21,1,1
answer_correctness_metric,147,20,1,1
my_custom_metric,107,20,1,1
specificity metric depth score,60,20,1,6
specificity metric llm rating,60,20,1,6
specificity metric llm score,60,20,1,6
specificity metric ner score,60,20,1,6
factual_accuracy,28,20,1,1
noise_sensitivity_mode_relevant,21,20,1,1
service_completeness,20,20,1,1
extracted_answer,20,19,1,1
noise_sensitivity_mode_irrelevant,20,19,1,1
sentiment_score,19,19,1,1
main_character_identification,26,18,1,1
custom_rouge,10395,17,1,1
context_entity_recall_2,69,16,1,1
custom_positivity_rubric,24,16,1,1
openai embeddings,24,16,1,1
custom_success_rubric,23,16,1,1
hit_metric,16,16,1,1
reasoning,16,16,1,1
custom_objective_rubric,23,15,1,1
correcteness,15,15,1,1
custom faithfulness,15,15,1,1
depth_of_understanding,15,15,1,1
answer_lcsrecall,97,14,1,4
service_validation,19,14,1,1
consciseness,47,13,1,1
specificity metric final score,39,13,1,2
procedure_steps_accuracy,33,13,1,1
logs_similarity,13,13,1,1
answer quality,946,12,1,1
coherenc_and_clarity_metric,236,12,1,1
sap_technical_accuracy,34,12,1,1
dependency_mapping,20,12,1,1
confidence_scoring,19,12,1,1
contradiction_detection,18,12,1,1
hallucination_severity,18,12,1,1
responserelevancy,14,12,1,1
fake_metric,12,12,1,1
response_quality,12,12,1,1
custom_interest_rubric,23,11,1,1
configuration_completeness,15,11,1,1
accuracy_check,14,11,1,1
country_comparison_rubric,11,11,1,1
country_identification_rubric,11,11,1,1
prompt_injection,11,11,1,1
technology_application_aspect,11,11,1,1
technology_application_rubric,11,11,1,1
trend_analysis_aspect,11,11,1,1
trend_analysis_rubric,11,11,1,1
context_precison,400,10,1,1
enthusiasm,100,10,1,1
bm25_metric,28,10,1,1
aws bedrock embeddings,24,10,1,1
cohere embeddings,23,10,1,1
verbose_factual_correctness,20,10,1,1
custom_readability,12,10,1,1
response_relevance,11,10,1,1
architecture_coverage,10,10,1,1
awareness_wins_rubric,10,10,1,1
bias_awareness_rubric,10,10,1,1
clarity_rubric,10,10,1,1
confidence_rubric,10,10,1,1
contextentityrecall,10,10,1,1
format_match,10,10,1,1
简洁性,26,9,1,1
key_info_presence,19,9,1,1
事实正确性,17,9,1,1
clarity_and_coherence,9,9,1,1
custom_professional_reference,9,9,1,1
flowvalidationsaccuracy_make_a_payment_amount_validation_2,9,9,1,1
gap_identification_rubric,9,9,1,1
grammatical_accuracy_and_spelling,9,9,1,1
organization_rubric,9,9,1,1
relevancy_and_factual_correctness,9,9,1,1
similarity_to_reference_answer,9,9,1,1
thoroughness_rubric,9,9,1,1
custom_bleu,11734,8,1,1
retrieve_truth,27,8,1,2
上下文召回率,14,8,1,1
response_fluency,12,8,1,1
context,11,8,1,1
response_conciseness,10,8,1,1
citation,9,8,1,1
expert_workflow,8,8,1,1
quality_metric,201,7,1,1
语义相似度,17,7,1,1
content_relevance,8,7,1,1
custom_safety,8,7,1,1
noisesensitivity_relevant,8,7,1,1
followup_question_relevancy,7,7,1,1
log_name_similarity,7,7,1,1
summarization,7,7,1,1
mutli sim,276,6,1,1
correctness_with_question,40,6,1,1
忠实度,17,6,1,1
issue_detection,14,6,1,1
dependency_management,10,6,1,1
answer_conciseness,8,6,1,1
base_image_specification,8,6,1,1
blueberry,8,6,1,1
fluency_score,8,6,1,1
grammar_quality,8,6,1,1
japanese_polite_aspect_critic,8,6,1,1
f1_score,7,6,1,1
math_correctness,7,6,1,1
novelty,7,6,1,1
usefulness,7,6,1,1
answer_gap,6,6,1,1
coarse_score,6,6,1,1
comprehensiveness,6,6,1,1
fact_checking,6,6,1,1
repitition,6,6,1,1
has_prohibited_words_or_synonyms,44,5,1,1
rubrics_score,33,5,1,1
answer_truth,19,5,1,1
relevancy,10,5,1,1
custom_toxicity_rubric,9,5,1,1
mexican_polite_aspect_critic,8,5,1,1
complexity,7,5,1,1
multimodal_faithfulness,7,5,1,1
language_quality,6,5,1,1
key_concepts_rubric,5,5,1,1
opinion_accuracy,5,5,1,1
sheep,5,5,1,1
online_q2c_acc,700,4,1,1
semantic_search_precision,80,4,1,1
answer_correctness1,16,4,1,1
banking compliance metric(aspect critic),7,4,1,1
insult_resilience,5,4,1,1
classic_context_precision,4,4,1,1
organization_critic,4,4,1,1
professionalism,4,4,1,1
agreement,19,3,1,1
policy_violation,12,3,1,1
ragas_hallucination,9,3,1,1
context_precision_llm,7,3,1,1
containerization_readiness,6,3,1,1
exerpt_accuracy,5,3,1,1
resource_requirements,5,3,1,1
biological_accuracy,3,3,1,1
context_recall_llm,3,3,1,1
context_utilization_relevant,3,3,1,1
convergence_score,3,3,1,1
custom_answer_correctness,3,3,1,1
disease_relevance,3,3,1,1
identify location,3,3,1,1
mechanism_clarity,3,3,1,1
same_number_of_entities,3,3,1,1
context_recall_nonllm,358,2,1,1
online_q2q_acc,300,2,1,1
text_image_mix,296,2,1,2
context_precision_nonllm,269,2,1,1
quote_exist_precision,170,2,1,2
jaccard_index,12,2,1,1
what_is,12,2,1,1
answer_correctness2,7,2,1,1
compare_summary_accuracy,5,2,1,1
criminality,5,2,1,1
answer_provided_metric,4,2,1,1
blueberry_metric,3,2,1,1
semantic similarity,3,2,1,1
actionability,2,2,1,1
error_link,2,2,1,1
fully_answered,2,2,1,1
judgment,2,2,1,1
malice,2,2,1,1
objectivity,2,2,1,1
patient triaged,2,2,1,1
raw_answer_correctness,151,1,1,1
answer_correctness_0.8_0.15,97,1,1,1
answer_correctness_1.0_0.0,97,1,1,1
verbosity,49,1,1,1
is_japanese,4,1,1,1
custom,3,1,1,1
not_blueberry,2,1,1,1
substring_similarity,2,1,1,1
a_fake_grained_score,1,1,1,1
answer_groundedness,1,1,1,1
aspect_critic,1,1,1,1
aspectcritic,1,1,1,1
bias_language,1,1,1,1
brand voice metric(aspect critic),1,1,1,1
clarity_check,1,1,1,1
contextrecall,1,1,1,1
educational,1,1,1,1
expert_tool_validation,1,1,1,1
expertise_score,1,1,1,1
explanation_clarity,1,1,1,1
faithfulness_score,1,1,1,1
goal_binary,1,1,1,1
harmfulbias,1,1,1,1
instruction_following,1,1,1,1
keyword_presence,1,1,1,1
not_received,1,1,1,1
relevance_check,1,1,1,1
simplecriteriascore,1,1,1,1
skill_relevance,1,1,1,1
summary_accurac,1,1,1,1
test_rubric,1,1,1,1
unranked_context_precision,1,1,1,1
